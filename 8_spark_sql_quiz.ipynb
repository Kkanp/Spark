{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling with Spark SQL Quiz\n",
    "\n",
    "This quiz uses the same dataset and most of the same questions from the earlier \"Quiz - Data Wrangling with Data Frames Jupyter Notebook.\" For this quiz, however, use Spark SQL instead of Spark Data Frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# TODOS: \n",
    "# 1) import any other libraries you might need\n",
    "# 2) instantiate a Spark session \n",
    "# 3) read in the data set located at the path \"data/sparkify_log_small.json\"\n",
    "# 4) create a view to use with your SQL queries\n",
    "# 5) write code to answer the quiz questions \n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql.functions import desc,asc\n",
    "from pyspark.sql.functions import sum as Fsum\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "spark = SparkSession.builder.appName(\"Quiz_SparkSQL\").getOrCreate()\n",
    "path = \"data/sparkify_log_small.json\"\n",
    "dt = spark.read.json(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|              artist|\n",
      "+--------------------+\n",
      "|       Showaddywaddy|\n",
      "|          Lily Allen|\n",
      "|Cobra Starship Fe...|\n",
      "+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt.select(['artist']).show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- artist: string (nullable = true)\n",
      " |-- auth: string (nullable = true)\n",
      " |-- firstName: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- itemInSession: long (nullable = true)\n",
      " |-- lastName: string (nullable = true)\n",
      " |-- length: double (nullable = true)\n",
      " |-- level: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- method: string (nullable = true)\n",
      " |-- page: string (nullable = true)\n",
      " |-- registration: long (nullable = true)\n",
      " |-- sessionId: long (nullable = true)\n",
      " |-- song: string (nullable = true)\n",
      " |-- status: long (nullable = true)\n",
      " |-- ts: long (nullable = true)\n",
      " |-- userAgent: string (nullable = true)\n",
      " |-- userId: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.createOrReplaceTempView(\"dt_table\") #dt_table can be used only in SQL command"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1\n",
    "\n",
    "Which page did user id \"\"(empty string) NOT visit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "| page|\n",
      "+-----+\n",
      "| Home|\n",
      "|About|\n",
      "|Login|\n",
      "| Help|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO: write your code to answer question 1\n",
    "spark.sql('''SELECT * FROM dt_table WHERE userId IS NULL''') #lazy transform, don't execute yet\n",
    "spark.sql('''SELECT DISTINCT page FROM dt_table WHERE userId = \"\"''').show()\n",
    "#Above are pages user id '' visited!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------------+\n",
      "|page|            page|\n",
      "+----+----------------+\n",
      "|null|Submit Downgrade|\n",
      "|null|       Downgrade|\n",
      "|null|          Logout|\n",
      "|null|   Save Settings|\n",
      "|null|        Settings|\n",
      "|null|        NextSong|\n",
      "|null|         Upgrade|\n",
      "|null|           Error|\n",
      "|null|  Submit Upgrade|\n",
      "+----+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''\n",
    "SELECT * FROM (SELECT DISTINCT page FROM dt_table WHERE userId = \"\") AS t1\n",
    "RIGHT JOIN (SELECT DISTINCT page FROM dt_table) AS t2\n",
    "ON t1.page = t2.page\n",
    "WHERE t1.page IS NULL\n",
    "''').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|            page|\n",
      "+----------------+\n",
      "|Submit Downgrade|\n",
      "|            Home|\n",
      "|       Downgrade|\n",
      "|          Logout|\n",
      "|   Save Settings|\n",
      "|           About|\n",
      "|        Settings|\n",
      "|           Login|\n",
      "|        NextSong|\n",
      "|            Help|\n",
      "|         Upgrade|\n",
      "|           Error|\n",
      "|  Submit Upgrade|\n",
      "+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''SELECT DISTINCT page FROM dt_table''').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2 - Reflect\n",
    "\n",
    "Why might you prefer to use SQL over data frames? Why might you prefer data frames over SQL?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#depends on which one you are more familiar and who you work with\n",
    "#dataframes are similar to pandas in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3\n",
    "\n",
    "How many female users do we have in the data set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------------------+\n",
      "|gender|count(DISTINCT userId)|\n",
      "+------+----------------------+\n",
      "|     F|                   462|\n",
      "|  null|                     1|\n",
      "|     M|                   501|\n",
      "+------+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO: write your code to answer question 3\n",
    "spark.sql('''SELECT gender, COUNT(DISTINCT userId) FROM dt_table GROUP BY gender''').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4\n",
    "\n",
    "How many songs were played from the most played artist?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|              artist|plays|\n",
      "+--------------------+-----+\n",
      "|            Coldplay|   83|\n",
      "|       Kings Of Leon|   69|\n",
      "|Florence + The Ma...|   52|\n",
      "|            BjÃÂ¶rk|   46|\n",
      "|       Dwight Yoakam|   45|\n",
      "+--------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO: write your code to answer question 4\n",
    "spark.sql('''\n",
    "SELECT artist, COUNT(artist) as plays\n",
    "FROM dt_table \n",
    "GROUP BY artist \n",
    "ORDER BY plays DESC\n",
    "LIMIT 5\n",
    "''').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|              artist|count|\n",
      "+--------------------+-----+\n",
      "|                null| 1653|\n",
      "|            Coldplay|   83|\n",
      "|       Kings Of Leon|   69|\n",
      "|Florence + The Ma...|   52|\n",
      "|            BjÃÂ¶rk|   46|\n",
      "|       Dwight Yoakam|   45|\n",
      "+--------------------+-----+\n",
      "only showing top 6 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#using data frame\n",
    "dt.select(['artist','song']).groupBy('artist').count().orderBy(desc('count')).show(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5 (challenge)\n",
    "\n",
    "How many songs do users listen to on average between visiting our home page? Please round your answer to the closest integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+-------------+-------+\n",
      "|userId|    page|           ts|is_home|\n",
      "+------+--------+-------------+-------+\n",
      "|  1046|NextSong|1513720872284|      0|\n",
      "|  1000|NextSong|1513720878284|      0|\n",
      "|  2219|NextSong|1513720881284|      0|\n",
      "|  2373|NextSong|1513720905284|      0|\n",
      "|  1747|    Home|1513720913284|      1|\n",
      "|  1162|NextSong|1513720955284|      0|\n",
      "|  1061|NextSong|1513720959284|      0|\n",
      "|   748|    Home|1513720959284|      1|\n",
      "|   597|    Home|1513720980284|      1|\n",
      "|  1806|NextSong|1513720983284|      0|\n",
      "+------+--------+-------------+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO: write your code to answer question 5\n",
    "\n",
    "#for SQL, use CASE whenever you need to define a new column\n",
    "#but it won't be saved to the origin table, so need to assign to a new table\n",
    "is_home = spark.sql('''\n",
    "SELECT userId, page, ts,\n",
    "CASE WHEN page = 'Home' THEN 1 ELSE 0 END AS is_home\n",
    "FROM dt_table\n",
    "WHERE (page = 'NextSong' OR page = 'Home')\n",
    "''')\n",
    "\n",
    "is_home.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+-------------+-------+------+\n",
      "|userId|    page|           ts|is_home|period|\n",
      "+------+--------+-------------+-------+------+\n",
      "|  2162|NextSong|1513781246284|      0|     0|\n",
      "|  2162|NextSong|1513781065284|      0|     0|\n",
      "|  2162|NextSong|1513780860284|      0|     0|\n",
      "|  2162|NextSong|1513780569284|      0|     0|\n",
      "|  2162|NextSong|1513780371284|      0|     0|\n",
      "|  2162|NextSong|1513780156284|      0|     0|\n",
      "|  2162|NextSong|1513779800284|      0|     0|\n",
      "|  2162|NextSong|1513779578284|      0|     0|\n",
      "|  2162|NextSong|1513779348284|      0|     0|\n",
      "|  2162|NextSong|1513778915284|      0|     0|\n",
      "|  2162|NextSong|1513778740284|      0|     0|\n",
      "|  2162|NextSong|1513778523284|      0|     0|\n",
      "|  2162|NextSong|1513778348284|      0|     0|\n",
      "|  2162|NextSong|1513778117284|      0|     0|\n",
      "|  2162|NextSong|1513777906284|      0|     0|\n",
      "|  2162|NextSong|1513777669284|      0|     0|\n",
      "|  2162|NextSong|1513777419284|      0|     0|\n",
      "|  2162|NextSong|1513777095284|      0|     0|\n",
      "|  2162|NextSong|1513776838284|      0|     0|\n",
      "|  2162|    Home|1513776699284|      1|     1|\n",
      "|  2162|    Home|1513776689284|      1|     2|\n",
      "|  2162|NextSong|1513776667284|      0|     2|\n",
      "|  2162|NextSong|1513776261284|      0|     2|\n",
      "|  2162|NextSong|1513776042284|      0|     2|\n",
      "|  2162|NextSong|1513775810284|      0|     2|\n",
      "+------+--------+-------------+-------+------+\n",
      "only showing top 25 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# keep the results in a new view (to be called again in SQL command)\n",
    "is_home.createOrReplaceTempView(\"is_home_table\")\n",
    "\n",
    "# find the cumulative sum over the is_home column\n",
    "cumulative_sum = spark.sql('''SELECT *, SUM(is_home) \n",
    "OVER (PARTITION BY userID ORDER BY ts DESC) AS period\n",
    "FROM is_home_table''')\n",
    "\n",
    "cumulative_sum.filter('userId=2162').show(25) #see example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+------+--------+\n",
      "|userId|    page|period|count(1)|\n",
      "+------+--------+------+--------+\n",
      "|  1436|NextSong|     0|       2|\n",
      "|  2088|NextSong|     1|      13|\n",
      "|  2162|NextSong|     0|      19|\n",
      "|  2162|NextSong|     2|      15|\n",
      "|  2294|NextSong|     0|       4|\n",
      "|  2294|NextSong|     1|      17|\n",
      "|  2294|NextSong|     2|       3|\n",
      "|  2294|NextSong|     3|      16|\n",
      "|  2294|NextSong|     4|       4|\n",
      "|  2294|NextSong|     5|      11|\n",
      "+------+--------+------+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cumulative_sum.createOrReplaceTempView(\"period_table\")\n",
    "\n",
    "spark.sql('''\n",
    "SELECT userId,page,period,COUNT(*) FROM period_table GROUP BY userId,page,period HAVING page ='NextSong'\n",
    "''').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+------+--------+\n",
      "|userId|    page|period|count(1)|\n",
      "+------+--------+------+--------+\n",
      "|  1436|NextSong|     0|       2|\n",
      "|  2088|NextSong|     1|      13|\n",
      "|  2162|NextSong|     0|      19|\n",
      "|  2162|NextSong|     2|      15|\n",
      "|  2294|NextSong|     0|       4|\n",
      "|  2294|NextSong|     1|      17|\n",
      "|  2294|NextSong|     2|       3|\n",
      "|  2294|NextSong|     3|      16|\n",
      "|  2294|NextSong|     4|       4|\n",
      "|  2294|NextSong|     5|      11|\n",
      "+------+--------+------+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''\n",
    "SELECT userId,page,period,COUNT(*) FROM period_table GROUP BY userId,page,period HAVING page ='NextSong'\n",
    "''').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|avg(countresults)|\n",
      "+-----------------+\n",
      "|6.898347107438017|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''\n",
    "SELECT AVG(countresults)\n",
    "FROM (SELECT COUNT(*) AS countresults FROM period_table GROUP BY userId,page,period HAVING page ='NextSong')\n",
    "''').show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
